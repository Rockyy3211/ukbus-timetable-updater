name: Build & publish TXC (NW + Scotland + Wales)

on:
  schedule:
    - cron: "0 3 * * 1"   # Mondays 03:00 UTC
  workflow_dispatch: {}

jobs:
  build:
    runs-on: ubuntu-latest
    permissions: { contents: read }
    env:
      CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
      CF_API_TOKEN:  ${{ secrets.CF_API_TOKEN }}
      KV_NAMESPACE_ID: ${{ secrets.KV_NAMESPACE_ID }}
      BODS_API_KEY:  ${{ secrets.BODS_API_KEY }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Use Node 20
        uses: actions/setup-node@v4
        with: { node-version: '20' }

      - name: Prepare dirs
        run: mkdir -p txc-build/downloads txc-build/shards

      - name: Install build deps
        working-directory: txc-build
        run: npm install --no-fund --no-audit

      - name: Download TXC datasets (NW + Scotland + Wales)
        shell: bash
        env:
          API: ${{ secrets.BODS_API_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${API:-}" ]; then
            echo "::error::BODS_API_KEY secret is missing."
            exit 1
          fi
          echo "::add-mask::$API"

          META_URL="https://data.bus-data.dft.gov.uk/api/v1/dataset/?limit=1000&status=published&api_key=$API"
          HTTP=$(curl -sS -H "Accept: application/json" -o datasets.json -w "%{http_code}" "$META_URL")
          echo "BODS metadata HTTP: $HTTP"
          if [ "$HTTP" != "200" ]; then
            echo "---- Response (first 800 chars) ----"
            head -c 800 datasets.json || true
            echo
            echo "::error::BODS API failed (HTTP $HTTP)."
            exit 1
          fi

          COUNT=$(jq '(.results // []) | length' datasets.json)
          echo "Metadata records: $COUNT"
          if [ "$COUNT" -eq 0 ]; then
            echo "::error::BODS returned 0 datasets."
            exit 1
          fi

          mkdir -p txc-build/downloads

          # Build list of valid URLs for:
          # - North West
          # - Scotland
          # - Wales
          jq -r '
            (.results // [])
            | map(
                select(
                  # ----- NAME-BASED HINTS (NW + Scotland + Wales) -----
                  ((.name // "" | tostring)
                    | test("(?i)("
                      + "north\\s*west|greater manchester|merseyside|lancashire|cumbria|cheshire|blackpool|blackburn|warrington|halton|westmorland|cumberland"
                      + "|scotland|glasgow|edinburgh|highland|aberdeen|dundee"
                      + "|wales|cymru|cardiff|swansea|newport"
                      + ")"
                    ))
                  or
                  # ----- ADMIN AREA MATCH (NW + Scotland + Wales) -----
                  (
                    ((.adminAreas // .admin_areas // [] )
                      | any(
                          ((.name // .Name // "" | tostring)
                            | test("(?i)("
                              # North West admin areas
                              + "Greater Manchester|Merseyside|Lancashire|Cumbria|Cheshire East|Cheshire West and Chester|Blackburn with Darwen|Blackpool|Warrington|Halton|Westmorland and Furness|Cumberland"
                              # Scotland admin areas
                              + "|Aberdeen|Aberdeenshire|Angus|Argyll and Bute|Clackmannanshire|Dumfries and Galloway|Dundee City|East Ayrshire|East Dunbartonshire|East Lothian|East Renfrewshire|City of Edinburgh|Falkirk|Fife|Glasgow City|Highland|Inverclyde|Midlothian|Moray|North Ayrshire|North Lanarkshire|Orkney Islands|Perth and Kinross|Renfrewshire|Scottish Borders|Shetland Islands|South Ayrshire|South Lanarkshire|Stirling|West Dunbartonshire|West Lothian|Western Isles|Na h-Eileanan Siar"
                              # Wales admin areas
                              + "|Isle of Anglesey|Gwynedd|Conwy|Denbighshire|Flintshire|Wrexham|Powys|Ceredigion|Pembrokeshire|Carmarthenshire|Swansea|Neath Port Talbot|Bridgend|Vale of Glamorgan|Cardiff|Rhondda Cynon Taf|Merthyr Tydfil|Caerphilly|Blaenau Gwent|Torfaen|Monmouthshire|Newport"
                              + ")")
                          )
                      )
                    )
                  )
                )
              )
            | map(
                [
                  (.download_url // empty),
                  (.url // empty),
                  ((.resources // [])[]? .url // empty)
                ]
                | map(select(type=="string" and test("^https?://")))
                | unique
              )
            | flatten
            | map(select( (endswith(".zip") or contains("/download/")) ))
            | .[:5000]
            | .[]
          ' datasets.json > urls.txt

          echo "Filtered URLs:"
          nl -ba urls.txt || true

          URL_COUNT=$(wc -l < urls.txt | tr -d ' ')
          echo "URL_COUNT=$URL_COUNT"
          if [ "$URL_COUNT" -eq 0 ]; then
            echo "::error::No valid download URLs after filtering."
            exit 1
          fi

          OK=0
          i=0
          while IFS= read -r u; do
            [ -z "$u" ] && continue
            i=$((i+1))
            printf -v OUT "txc-build/downloads/dataset-%03d.zip" "$i"
            echo "Downloading $u -> $OUT"
            if curl -fLs "$u" -o "$OUT"; then
              OK=$((OK+1))
            else
              echo "::warning::Failed $u"
              rm -f "$OUT" || true
            fi
          done < urls.txt

          echo "Successful downloads (raw): $OK"
          DL_COUNT=$(find txc-build/downloads -maxdepth 1 -type f -name 'dataset-*.zip' | wc -l | tr -d ' ')
          echo "ZIPs present (raw): $DL_COUNT"
          if [ "$DL_COUNT" -eq 0 ]; then
            echo "::error::No TXC ZIPs were downloaded."
            exit 1
          fi

      # ðŸ” Validate ZIPs and drop any corrupt ones
      - name: Validate TXC ZIPs
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob

          echo "Validating downloaded ZIPs..."
          for f in txc-build/downloads/dataset-*.zip; do
            echo "Testing $f"
            if ! unzip -tqq "$f"; then
              echo "::warning::Invalid ZIP, removing $f"
              rm -f "$f"
            fi
          done

          VALID_COUNT=$(find txc-build/downloads -maxdepth 1 -type f -name 'dataset-*.zip' | wc -l | tr -d ' ')
          echo "Valid ZIPs after validation: $VALID_COUNT"
          if [ "$VALID_COUNT" -eq 0 ]; then
            echo "::error::No valid TXC ZIPs after validation."
            exit 1
          fi

      - name: Build stopâ†’services index
        working-directory: txc-build
        run: npm run build

      - name: Shard JSON
        working-directory: txc-build
        run: npm run shard

      - name: Install wrangler
        run: npm i -g wrangler

      # Upload each shard JSON as a single KV key: shard:XXXX
      - name: Upload shard JSON to Cloudflare KV
        working-directory: txc-build/shards
        env:
          KV_NAMESPACE_ID: ${{ secrets.KV_NAMESPACE_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN }}  # wrangler v3 expects this
        run: |
          set -euo pipefail

          if [ -z "${KV_NAMESPACE_ID:-}" ]; then
            echo "::error::KV_NAMESPACE_ID secret missing"
            exit 1
          fi
          if [ -z "${CLOUDFLARE_API_TOKEN:-}" ]; then
            echo "::error::CF_API_TOKEN (mapped to CLOUDFLARE_API_TOKEN) missing"
            exit 1
          fi

          for f in *.json; do
            prefix="${f%.json}"         # e.g. 1800.json -> 1800
            key="shard:${prefix}"
            echo "Uploading shard file $f as KV key '$key'"
            wrangler kv key put "$key" \
              --namespace-id "$KV_NAMESPACE_ID" \
              --path "$f" \
              --remote
          done

      - name: Done
        run: echo "KV updated."
