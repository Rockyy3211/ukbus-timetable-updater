- name: Download TXC datasets (North West)
  shell: bash
  env:
    API: ${{ secrets.BODS_API_KEY }}
  run: |
    set -euo pipefail

    if [ -z "${API:-}" ]; then
      echo "::error::BODS_API_KEY secret is missing."; exit 1
    fi
    echo "::add-mask::$API"

    META_URL="https://data.bus-data.dft.gov.uk/api/v1/dataset/?limit=1000&status=published&api_key=$API"
    HTTP=$(curl -sS -H "Accept: application/json" -o datasets.json -w "%{http_code}" "$META_URL")
    echo "BODS metadata HTTP: $HTTP"
    if [ "$HTTP" != "200" ]; then
      echo "---- Response (first 800 chars) ----"
      head -c 800 datasets.json || true
      echo
      echo "::error::BODS API failed (HTTP $HTTP). Check BODS_API_KEY."; exit 1
    fi

    COUNT=$(jq '(.results // []) | length' datasets.json)
    echo "Metadata records: $COUNT"
    if [ "$COUNT" -eq 0 ]; then
      echo "::error::BODS returned 0 datasets."; exit 1
    fi

    mkdir -p txc-build/downloads

    # Build list of valid URLs from name/admin area-filtered datasets
    jq -r '
      (.results // [])
      | map(
          select(
            ((.name // "" | tostring)
              | test("(?i)(north\\s*west|greater manchester|merseyside|lancashire|cumbria|cheshire|blackpool|blackburn|warrington|halton|westmorland|cumberland)"))
            or
            (
              ((.adminAreas // .admin_areas // [])
                | any(
                    ((.name // .Name // "" | tostring)
                      | test("(?i)(Greater Manchester|Merseyside|Lancashire|Cumbria|Cheshire East|Cheshire West and Chester|Blackburn with Darwen|Blackpool|Warrington|Halton|Westmorland and Furness|Cumberland)"))
                  )
              )
            )
          )
        )
      | map(
          [
            (.download_url // empty),
            (.url // empty),
            ((.resources // [])[]? .url // empty)
          ]
          | map(select(type=="string" and test("^https?://")))
          | unique
        )
      | flatten
      | map(select( (endswith(".zip") or contains("/download/")) ))
      | .[:10]  # limit for first run; remove later
      | .[]
    ' datasets.json > urls.txt

    echo "Filtered URLs:"
    nl -ba urls.txt || true

    URL_COUNT=$(wc -l < urls.txt | tr -d ' ')
    if [ "$URL_COUNT" -eq 0 ]; then
      echo "::error::No valid download URLs after filtering."
      echo "Dumping two matching datasets for inspection:"
      jq -C '
        (.results // [])
        | map(select((.name // "" | test("(?i)(north\\s*west|greater manchester|merseyside|lancashire|cumbria|cheshire|blackpool|blackburn|warrington|halton|westmorland|cumberland)"))) 
        | .[:2])
        | .[]
        | {name, download_url, url, resources}
      ' datasets.json | head -n 200 || true
      exit 1
    fi

    # Download with curl -f (fail on HTTP error). If one URL fails, we keep going.
    # We also count how many succeeded.
    OK=0
    while IFS= read -r u; do
      [ -z "$u" ] && continue
      OUT="txc-build/downloads/$(basename "$u")"
      echo "Downloading $u -> $OUT"
      if curl -fLs "$u" -o "$OUT"; then
        OK=$((OK+1))
      else
        echo "::warning::Failed to download $u"
        rm -f "$OUT" || true
      fi
    done < urls.txt

    echo "Successful downloads: $OK"
    # Safe count with find (won't trip set -e/pipefail)
    DL_COUNT=$(find txc-build/downloads -maxdepth 1 -type f -name '*.zip' | wc -l | tr -d ' ')
    echo "ZIPs present: $DL_COUNT"
    if [ "$DL_COUNT" -eq 0 ]; then
      echo "::error::No TXC ZIPs were downloaded."; exit 1
    fi
